#!/usr/bin/env python
# coding: utf-8

# In[5]:


import altair as alt
import pandas as pd
import folium  
import altair as alt
import pydeck as pdk
import plotly.express as px
import plotly.graph_objects as go
import plotly.io as pio
from plotly.subplots import make_subplots 
pio.renderers.default='notebook_connected' 
import warnings
warnings.filterwarnings("ignore")


# In[6]:


import sys
print(sys.executable)


# In[49]:


from itertools import combinations
from collections import Counter
import networkx as nx
import matplotlib.pyplot as plt
import re
from konlpy.tag import Okt
import streamlit as st


# In[8]:


# ì´ì „ ì‚¬ìš©í–ˆì—ˆë˜ ì½”ë“œ ê¸°ë°˜ìœ¼ë¡œ ì´ˆê¸° ì‘ì„± ë„¤ì´ë²„ api ë¡œ ì‘ì„±


# In[9]:


import os
import sys
import urllib.request
import urllib.parse
import urllib.error
import pandas as pd
import json

# ë„¤ì´ë²„ì—ì„œ ë°œê¸‰ë°›ì€ í´ë¼ì´ì–¸íŠ¸ IDì™€ ì‹œí¬ë¦¿ ì‚¬ìš©
client_id = "l_TbyQUetE38ozvKUt1g"
client_secret = "Hc8Dk9xHXi"

# íŒŒë¼ë¯¸í„° ì„¤ì •
display_count = 100          # í•œ í˜ì´ì§€ì— í‘œì‹œí•  ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
num_data = 1000              # ì „ì²´ ê²€ìƒ‰ ë°ì´í„° ê°œìˆ˜
sort = "date"                # ì •ë ¬ ê¸°ì¤€ (date:ë‚ ì§œìˆœ, sim:ìœ ì‚¬ë„ìˆœ)

# ê²€ìƒ‰í•  ë‹¨ì–´ì˜ URL ì¸ì½”ë”©
encText = urllib.parse.quote("KíŒ ë°ëª¬ í—Œí„°ìŠ¤ íŒ¬ë¤")

# ê²°ê³¼ë¥¼ ì €ì¥í•  list ìƒì„±
results = []

# forë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í˜ì´ì§€ë³„ë¡œ ìš”ì²­
for idx in range(0, num_data, display_count):

    # JSON ê²°ê³¼ ìš”ì²­ìš© URL ìƒì„±
    url = (
        "https://openapi.naver.com/v1/search/news.json"
        + f"?query={encText}&start={idx+1}&display={display_count}&sort={sort}"
    )

    # ìš”ì²­ ê°ì²´ ìƒì„±
    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", client_id)
    request.add_header("X-Naver-Client-Secret", client_secret)

    try:
        # ìš”ì²­ ë³´ë‚´ê³  ì‘ë‹µ ë°›ê¸°
        response = urllib.request.urlopen(request)
        rescode = response.getcode()

        if rescode == 200:  # ì‘ë‹µ ì½”ë“œê°€ 200ì´ë©´ ì„±ê³µ
            response_body = response.read()
            response_dict = json.loads(response_body.decode("utf-8"))
            results += response_dict["items"]
        else:
            print("Error Code:", rescode)

    except urllib.error.HTTPError as e:
        print("HTTPError:", e.code)
        print("Response body:", e.read().decode("utf-8"))
        break

print(f"ì´ ë°ì´í„° ê°œìˆ˜: {len(results)}")

# pandas DataFrameìœ¼ë¡œ í™•ì¸í•´ë³´ê³  ì‹¶ìœ¼ë©´
df = pd.DataFrame(results)

print(df.head())

df.to_csv("kíŒresults.csv", index=False, encoding="utf-8-sig")



# In[10]:


import pandas as pd
from itertools import combinations
from collections import Counter
import networkx as nx
import matplotlib.pyplot as plt
import re
from konlpy.tag import Okt

# ìˆ˜ì§‘í•œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv(r"C:\Users\shinchaewon\Desktop\ë°ì´í„°ì‹œê°í™”\3ì°¨ì‹œí—˜\kíŒresults.csv")

df.head()


# In[11]:


descriptions = df["description"].dropna().tolist()


# In[12]:


# ì˜¤ë¥˜ ë¬¸ì œë¡œ okt ê²½ë¡œë¬¸ì œë¡œ llm ì”€


# In[13]:


from konlpy.tag import Okt

okt = Okt(
    jvmpath=r"C:\Users\shinchaewon\anaconda3\envs\rstudio-_1\Library\bin\server\jvm.dll"
)
print(okt.morphs("ìë°” ê²½ë¡œ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤"))



# In[14]:


okt = Okt()

# ë¶ˆìš©ì–´ ì‚¬ì „ ë¶ˆëŸ¬ì˜¤ê¸°
with open(
    r"C:\Users\shinchaewon\Desktop\ë°ì´í„°ì‹œê°í™”\stopword.txt",
    "r",
    encoding="utf-8"
) as f:
    stopwords = f.read().splitlines()

# ë¶ˆìš©ì–´ ì¶”ê°€
stopwords.extend( [
    "ê¸°ì", "ë³´ë„", "ë‰´ìŠ¤", "ê¸°ì‚¬", "ì‚¬ì§„",
    "ë°í˜”ë‹¤", "ì „í–ˆë‹¤", "ë§í–ˆë‹¤", "ì„¤ëª…í–ˆë‹¤",
    "ì´ë²ˆ", "ì§€ë‚œ", "ë‹¹ì‹œ", "ìµœê·¼",
    "ê´€ë ¨", "í†µí•´", "ëŒ€í•´", "ë“±",
    "í•œí¸", "ë˜í•œ", "ê·¸ëŸ¬ë‚˜", "í•˜ì§€ë§Œ",
    "ìœ„í•´", "ë•Œë¬¸", "ê²½ìš°", "ì‚¬ì‹¤"
]
)


# In[15]:


all_nouns = []

for text in descriptions:
    # í•œê¸€ + ê³µë°±ë§Œ ë‚¨ê¸°ê¸°
    text_cleaned = re.sub(r"[^ê°€-í£\s]", "", text)

    # ëª…ì‚¬ ì¶”ì¶œ
    nouns = okt.nouns(text_cleaned)

    # í•œ ê¸€ì ì œê±° + ë¶ˆìš©ì–´ ì œê±° + ì¤‘ë³µ ì œê±°
    nouns = [
        word for word in set(nouns)
        if len(word) > 1 and word not in stopwords
    ]

    all_nouns.append(nouns)

print(all_nouns[:5])


# In[16]:


edge_list = []

for nouns in all_nouns:
    if len(nouns) > 1:
        edge_list.extend(combinations(sorted(nouns), 2))

edge_counts = Counter(edge_list)

print(edge_counts.most_common(10))


# In[17]:


min_count = 20

filtered_edges = {
    edge: weight
    for edge, weight in edge_counts.items()
    if weight >= min_count
}

print("í•„í„°ë§ëœ ì—£ì§€ ìˆ˜:", len(filtered_edges))


# In[18]:


G = nx.Graph()

weighted_edges = [
    (u, v, w) for (u, v), w in filtered_edges.items()
]

G.add_weighted_edges_from(weighted_edges)


# In[19]:


st.markdown("---")

import streamlit as st

st.subheader("ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ê¸°ë°˜ í•µì‹¬ í•´ì„")

st.markdown("""
ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì—ëŠ” **KíŒ, ìŒì•…, ì•„ì´ëŒ, ê·¸ë£¹, ì•¨ë²”** ê´€ë ¨ í‚¤ì›Œë“œê°€ ë°€ì§‘ë˜ì–´ ìˆìœ¼ë©°,  
ì´ì™€ í•¨ê»˜ **ì„¸ê³„, í•´ì™¸, ë¯¸êµ­** ë“± ê¸€ë¡œë²Œ í™•ì¥ í‚¤ì›Œë“œê°€ ê°•í•˜ê²Œ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  
ì´ëŠ” í•´ë‹¹ ì½˜í…ì¸ ê°€ ë‹¨ìˆœí•œ ì• ë‹ˆë©”ì´ì…˜ì´ ì•„ë‹ˆë¼  
**KíŒ ì‚°ì—…ì˜ ê¸€ë¡œë²Œ í™•ì¥ ì‚¬ë¡€ë¡œ ì¸ì‹ë˜ê³  ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.**

ë˜í•œ **ë„·í”Œë¦­ìŠ¤, ê³µê°œ, ì‹œì‘, í™•ì‚°, í”Œë«í¼** í‚¤ì›Œë“œê°€ ì¤‘ì‹¬ë¶€ì— ìœ„ì¹˜í•´ ìˆì–´,  
íŒ¬ë¤ í˜•ì„± ê³¼ì •ì—ì„œ **ì½˜í…ì¸  ìì²´ë¿ ì•„ë‹ˆë¼ ë„·í”Œë¦­ìŠ¤ ìœ í†µ êµ¬ì¡°ê°€ ì¤‘ìš”í•œ ì´‰ë§¤ ì—­í• **ì„ í–ˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  
ì´ë¡œ ì¸í•´ **íŠ¹ì • ìš”ì¼ì— ê¸°ì‚¬ì™€ ê´€ì‹¬ì´ ì§‘ì¤‘ë˜ëŠ” í˜„ìƒ**ì´ ë°œìƒí–ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.

í•œí¸ **ë…¸ë˜, OST, ìŒì›, í¼í¬ë¨¼ìŠ¤** í‚¤ì›Œë“œê°€ ë‹¤ìˆ˜ ì—°ê²°ë˜ì–´ ë‚˜íƒ€ë‚˜,  
ì„œì‚¬ ì¤‘ì‹¬ë³´ë‹¤ëŠ” **ìŒì•… ì†Œë¹„ë¥¼ í†µí•´ íŒ¬ì´ ìœ ì…ë˜ê³  íŒ¬ë¤ìœ¼ë¡œ í™•ì¥ë˜ëŠ” êµ¬ì¡°**ê°€ ëšœë ·í•˜ê²Œ í™•ì¸ë©ë‹ˆë‹¤.  
ì´ëŠ” ê¸°ì¡´ **KíŒ íŒ¬ì¸µì´ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ì…ëœ ë°°ê²½**ìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")


# In[20]:


pos = nx.spring_layout(G, k=0.3, iterations=50, seed=42)

node_sizes = [G.degree(node) * 100 for node in G.nodes()]
edge_widths = [G[u][v]["weight"] * 0.05 for u, v in G.edges()]

plt.figure(figsize=(15, 15))

nx.draw_networkx(
    G,
    pos,
    with_labels=True,
    node_size=node_sizes,
    width=edge_widths,
    font_size=12,
    node_color="skyblue",
    edge_color="gray",
    alpha=0.8
)

plt.title("ì¼€ì´íŒë°ëª¬í—Œí„°ìŠ¤ íŒ¬ë¤ì— ëŒ€í•œ ë„¤ì´ë²„ ë‰´ìŠ¤ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬", fontsize=20)
plt.axis("off")



# In[21]:


import networkx as nx
import matplotlib.pyplot as plt
# -----------------------------
# ë„¤íŠ¸ì›Œí¬ ë ˆì´ì•„ì›ƒ ì„¤ì •
# -----------------------------
pos = nx.spring_layout(G, k=0.3, iterations=50, seed=42)

node_sizes = [G.degree(node) * 100 for node in G.nodes()]
edge_widths = [G[u][v]["weight"] * 0.05 for u, v in G.edges()]

# -----------------------------
# Matplotlib Figure ìƒì„±
# -----------------------------
plt.figure(figsize=(15, 15))

nx.draw_networkx(
    G,
    pos,
    with_labels=True,
    node_size=node_sizes,
    font_size=12,
    node_color="skyblue",
    edge_color="gray",
    alpha=0.8
)

plt.title(
    "ì¼€ì´íŒë°ëª¬í—Œí„°ìŠ¤ íŒ¬ë¤ì— ëŒ€í•œ ë„¤ì´ë²„ ë‰´ìŠ¤ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬",
    fontsize=20
)
plt.axis("off")



# In[22]:


import streamlit as st
from PIL import Image

img_path = r"C:\Users\shinchaewon\Desktop\ë„¤íŠ¸ì›Œí¬ ê²°ê³¼.png"
img = Image.open(img_path)

st.subheader("ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ê²°ê³¼")

# ğŸ”¹ ë²„íŠ¼ ìœ„ì ¯
if st.button("ë„¤íŠ¸ì›Œí¬ ê²°ê³¼ ì´ë¯¸ì§€ ë³´ê¸°"):
    st.image(img, caption="ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ê²°ê³¼", use_container_width=True)




# In[23]:


import pandas as pd

path = r"C:\Users\shinchaewon\Desktop\KC_KOREA_CLTUR_CNTNTS_GENRE_OBSTRC_FCTR_INFO_2024.csv"

df = pd.read_csv(path, encoding="utf-8-sig")

df.head()


# In[24]:


df.info()


# In[25]:


# í•œë¥˜ ì‹¤íƒœì¡°ì‚¬ ë°ì´í„° 


# In[26]:


df = df.rename(columns={
    "OBSTRC_FCTR_CN": "ì €í•´ìš”ì¸",
    "ALL_TOTAL_CO": "ì‘ë‹µììˆ˜",
    "MALE_RATE": "ë‚¨ì„±ë¹„ìœ¨",
    "FEMALE_RATE": "ì—¬ì„±ë¹„ìœ¨",
    "ALL_N10S_RATE": "10ëŒ€ë¹„ìœ¨",
    "ALL_N20S_RATE": "20ëŒ€ë¹„ìœ¨",
    "ALL_N30S_RATE": "30ëŒ€ë¹„ìœ¨",
    "ALL_N40S_RATE": "40ëŒ€ë¹„ìœ¨",
    "ALL_N50S_RATE": "50ëŒ€ì´ìƒë¹„ìœ¨",
    "REPRT_YEAR_CN": "ì¡°ì‚¬ì—°ë„",
    "EXAMIN_COUNTRY_NM": "êµ­ê°€",
    "CNTNTS_URL": "ì¶œì²˜URL"
})


# In[27]:


st.title("í•œë¥˜ ì½˜í…ì¸  ì €í•´ìš”ì¸ ë¶„ì„")
st.subheader("ê²°ê³¼ í•´ì„")

st.markdown("""
**í•µì‹¬ ìš”ì•½**
-í¬ê²Œ ë³´ì´ëŠ” ë¬¸êµ¬ì¸ **â€˜í•œêµ­ê³¼ ìêµ­ì˜ ì •ì¹˜Â·ì™¸êµ ê´€ê³„â€™**ëŠ” ì½˜í…ì¸  í’ˆì§ˆê³¼ ë³„ê°œë¡œ, **êµ­ê°€ ê°„ ê´€ê³„/ì •ì±…/ì—¬ë¡ **ì´ í•œë¥˜ ìˆ˜ìš©ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  
 **ì™¸êµÂ·ì •ì¹˜ ìš”ì¸**ì€ íŠ¹ì • êµ­ê°€/ì‹œê¸°ì—ì„œ í•œë¥˜ í™•ì‚°ì„ ì œí•œí•  ìˆ˜ ìˆëŠ” ì™¸ìƒ ë³€ìˆ˜ë¡œ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")


# In[33]:


import sys
print(sys.executable)
from wordcloud import WordCloud
print("wordcloud OK")


# In[34]:


import streamlit as st
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from collections import Counter

st.subheader("ì €í•´ìš”ì¸ ì›Œë“œí´ë¼ìš°ë“œ")

# 1) ì €í•´ìš”ì¸ í…ìŠ¤íŠ¸ ì •ë¦¬
texts = (
    df["ì €í•´ìš”ì¸"]
    .dropna()
    .astype(str)
    .str.strip()
)
texts = texts[texts != ""]

freq = Counter(texts)

# 2) ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
font_path = r"C:\Windows\Fonts\malgun.ttf"
wc = WordCloud(
    font_path=font_path,
    width=900,
    height=600,
    background_color="white",
    max_words=80,
    collocations=False
).generate_from_frequencies(freq)

fig, ax = plt.subplots(figsize=(10, 7))
ax.imshow(wc)
ax.axis("off")

st.pyplot(fig)

# ë©”ëª¨ë¦¬/ì¤‘ë³µ ì¶œë ¥ ë°©ì§€
plt.close(fig)


# In[ ]:


st.title("í•œë¥˜ ì½˜í…ì¸  ì €í•´ìš”ì¸ ë¶„ì„")
st.subheader("ê²°ê³¼ í•´ì„")

st.markdown("""
**í•µì‹¬ ìš”ì•½**
-í¬ê²Œ ë³´ì´ëŠ” ë¬¸êµ¬ì¸ **â€˜í•œêµ­ê³¼ ìêµ­ì˜ ì •ì¹˜Â·ì™¸êµ ê´€ê³„â€™**ëŠ” ì½˜í…ì¸  í’ˆì§ˆê³¼ ë³„ê°œë¡œ, **êµ­ê°€ ê°„ ê´€ê³„/ì •ì±…/ì—¬ë¡ **ì´ í•œë¥˜ ìˆ˜ìš©ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  
 **ì™¸êµÂ·ì •ì¹˜ ìš”ì¸**ì€ íŠ¹ì • êµ­ê°€/ì‹œê¸°ì—ì„œ í•œë¥˜ í™•ì‚°ì„ ì œí•œí•  ìˆ˜ ìˆëŠ” ì™¸ìƒ ë³€ìˆ˜ë¡œ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")


# In[29]:


import streamlit as st
import pandas as pd

st.set_page_config(layout="wide")
st.title("í•œë¥˜ ì½˜í…ì¸  ì €í•´ìš”ì¸ ë¶„ì„")

# ======================
# ì‚¬ì´ë“œë°” í•„í„°
# ======================
st.sidebar.header("í•„í„°")

year = st.sidebar.selectbox(
    "ì¡°ì‚¬ì—°ë„ ì„ íƒ",
    sorted(df["ì¡°ì‚¬ì—°ë„"].unique())
)

country = st.sidebar.selectbox(
    "êµ­ê°€ ì„ íƒ",
    sorted(df["êµ­ê°€"].unique())
)

# í•„í„° ì ìš©
df_f = df[(df["ì¡°ì‚¬ì—°ë„"] == year) & (df["êµ­ê°€"] == country)]


# In[35]:


import koreanize_matplotlib


# In[39]:


import seaborn as sns


# In[37]:


st.subheader("ì €í•´ìš”ì¸ TOP 10 (Seaborn)")

top10 = (
    df_f.groupby("ì €í•´ìš”ì¸", as_index=False)["ì‘ë‹µììˆ˜"]
    .sum()
    .sort_values("ì‘ë‹µììˆ˜", ascending=False)
    .head(10)
)

fig, ax = plt.subplots(figsize=(8, 5))
sns.barplot(
    data=top10,
    x="ì‘ë‹µììˆ˜",
    y="ì €í•´ìš”ì¸",
    ax=ax
)

ax.set_title("ì €í•´ìš”ì¸ TOP 10")
ax.set_xlabel("ì‘ë‹µììˆ˜")
ax.set_ylabel("ì €í•´ìš”ì¸")

st.pyplot(fig)
plt.close(fig)


# In[38]:


st.title("í•œë¥˜ ì½˜í…ì¸  ì €í•´ìš”ì¸ ë¶„ì„")
st.subheader("ê²°ê³¼ í•´ì„")

st.markdown("""
**í•µì‹¬ ìš”ì•½**
ì—°ë ¹ëŒ€ê°€ ë†’ì•„ì§ˆìˆ˜ë¡(íŠ¹íˆ 50ëŒ€ ì´ìƒ) í•œë¥˜ ì½˜í…ì¸ ì— ëŒ€í•œ ì €í•´ ì¸ì‹ ë¹„ìœ¨ì´ ì „ë°˜ì ìœ¼ë¡œ ë†’ìœ¼ë©°, ì €í•´ìš”ì¸ì˜ ì„±ê²©ë„ â€˜ì–¸ì–´Â·ë¬¸í™” ì´í•´â€™ì—ì„œ â€˜ì½˜í…ì¸  ì í•©ì„±Â·ê°€ì¹˜ ì¸ì‹â€™ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.""")


# In[31]:


import altair as alt

st.subheader("ì—°ë ¹ëŒ€ë³„ ì €í•´ìš”ì¸ ë¹„ìœ¨ (Altair)")

age_cols = ["10ëŒ€ë¹„ìœ¨", "20ëŒ€ë¹„ìœ¨", "30ëŒ€ë¹„ìœ¨", "40ëŒ€ë¹„ìœ¨", "50ëŒ€ì´ìƒë¹„ìœ¨"]

df_long = df_f.melt(
    id_vars=["ì €í•´ìš”ì¸"],
    value_vars=age_cols,
    var_name="ì—°ë ¹ëŒ€",
    value_name="ë¹„ìœ¨"
)

chart = (
    alt.Chart(df_long)
    .mark_bar()
    .encode(
        x=alt.X("ë¹„ìœ¨:Q", title="ë¹„ìœ¨"),
        y=alt.Y("ì €í•´ìš”ì¸:N", sort="-x"),
        color="ì—°ë ¹ëŒ€:N",
        tooltip=["ì €í•´ìš”ì¸", "ì—°ë ¹ëŒ€", "ë¹„ìœ¨"]
    )
    .properties(height=400)
)

st.altair_chart(chart, use_container_width=True)


# In[ ]:





# In[48]:


import streamlit as st
import plotly.express as px

st.subheader("ì €í•´ìš”ì¸ ë¹„ìœ¨ (Donut)")
st.markdown("""
ì €í•´ìš”ì¸ ë¹„ì¤‘ì„ ìˆœì„œëŒ€ë¡œ ì‚´í´ë³´ë©´, í•œë¥˜ ì½˜í…ì¸  ì†Œë¹„ë¥¼ ê°€ì¥ í¬ê²Œ ì €í•´í•˜ëŠ” ìš”ì¸ì€ í•œêµ­ì–´ê°€ ì–´ë µê³  ìƒì†Œí•˜ë‹¤ëŠ” ì¸ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤. ê·¸ ë‹¤ìŒìœ¼ë¡œëŠ” ìë§‰ì´ë‚˜ ë”ë¹™ì„ í†µí•œ ì‹œì²­ ê³¼ì •ì˜ ë¶ˆí¸í•¨ì´ ë’¤ë¥¼ ì´ì–´, ì–¸ì–´ ì´í•´ì™€ ê´€ë ¨ëœ ë¬¸ì œê°€ ìƒìœ„ ìš”ì¸ì„ í˜•ì„±í•˜ê³  ìˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´í›„ì—ëŠ” ìêµ­ê³¼ì˜ ì •ì¹˜Â·ì™¸êµì  ê´€ê³„ê°€ ì¤‘ìš”í•œ ì €í•´ìš”ì¸ìœ¼ë¡œ ë‚˜íƒ€ë‚˜, ë¬¸í™” ì½˜í…ì¸  ìˆ˜ìš©ì´ ì™¸ë¶€ í™˜ê²½ì˜ ì˜í–¥ì„ ë°›ëŠ”ë‹¤ëŠ” ì ì„ ë³´ì—¬ì¤€ë‹¤. ê·¸ ë‹¤ìŒ ë‹¨ê³„ì—ì„œëŠ” ë¹„ìš© ë¶€ë‹´ê³¼ í•œêµ­ì ì¸ ìƒ‰ì±„ê°€ ê°•í•˜ë‹¤ëŠ” ì¸ì‹ì´ ì£¼ìš” ìš”ì¸ìœ¼ë¡œ ì´ì–´ì§€ë©°, ì½˜í…ì¸  ë° ìƒí’ˆì˜ í˜„ì§€ ì í•©ì„± ë¬¸ì œê°€ ë‚˜íƒ€ë‚œë‹¤. ì´í›„ì—ëŠ” ê°€ê²© ëŒ€ë¹„ í’ˆì§ˆ, ì½˜í…ì¸ ì˜ ë‹¤ì–‘ì„±, ì†Œì¬Â·ìŠ¤í† ë¦¬ì˜ ì§„ë¶€í•¨, ë¬¸í™”ì  ì´í•´ì˜ ì–´ë ¤ì›€ ë“±ì´ ë¹„êµì  ë¹„ìŠ·í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë¶„í¬í•˜ë©°, ì „ë°˜ì ìœ¼ë¡œ ì–¸ì–´Â·ë¬¸í™”Â·í˜„ì§€í™” ìš”ì¸ì´ ë³µí•©ì ìœ¼ë¡œ ì‘ìš©í•˜ê³  ìˆëŠ” êµ¬ì¡°ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
""")

st.markdown("""
ìœ„ì ¯ì´ ì‹¤í–‰ë˜ëŠ”ë° ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŒ""")
#  ìœ„ì ¯ 1: TOP N ì„ íƒ
top_n = st.slider(
    "ìƒìœ„ ì €í•´ìš”ì¸ ê°œìˆ˜ ì„ íƒ",
    min_value=5,
    max_value=15,
    value=10,
    step=1
)

# ======================
# ìœ„ì ¯ 2: ì •ë ¬ ê¸°ì¤€ ì„ íƒ

sort_order = st.radio(
    "ì •ë ¬ ê¸°ì¤€ ì„ íƒ",
    ["ì‘ë‹µììˆ˜ ë§ì€ ìˆœ", "ì‘ë‹µììˆ˜ ì ì€ ìˆœ"]
)

# ======================
# ë°ì´í„° ì •ë ¬ ë° TOP N ì ìš©
# ======================
topN = (
    df_f.groupby("ì €í•´ìš”ì¸", as_index=False)["ì‘ë‹µììˆ˜"]
    .sum()
)

if sort_order == "ì‘ë‹µììˆ˜ ë§ì€ ìˆœ":
    topN = topN.sort_values("ì‘ë‹µììˆ˜", ascending=False)
else:
    topN = topN.sort_values("ì‘ë‹µììˆ˜", ascending=True)

topN = topN.head(top_n)

# ======================
# ë„ë„› ì°¨íŠ¸
# ======================
fig = px.pie(
    topN,
    names="ì €í•´ìš”ì¸",
    values="ì‘ë‹µììˆ˜",
    hole=0.4,
    title=f"ì €í•´ìš”ì¸ ë¹„ìœ¨ (TOP {top_n})"
)

st.plotly_chart(fig, use_container_width=True)


# In[ ]:




